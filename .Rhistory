BV.MC.Entry.data.AB$unique.Line.ID)
BV.MC.Entry.data.AB$unique.Line.ID = ifelse(is.na(BV.MC.Entry.data.AB$unique.Line.ID),
BV.MC.Entry.data.AB$`InbName`,
BV.MC.Entry.data.AB$unique.Line.ID)
BV.MC.Entry.data.AB$unique.Line.ID = ifelse(BV.MC.Entry.data.AB$unique.Line.ID=="",
as.character(BV.MC.Entry.data.AB$Pedigree),
BV.MC.Entry.data.AB$unique.Line.ID)
BV.MC.Entry.data.AB$unique.Line.ID = ifelse(is.na(BV.MC.Entry.data.AB$unique.Line.ID),
as.character(BV.MC.Entry.data.AB$Pedigree),
BV.MC.Entry.data.AB$unique.Line.ID)
BV.MC.Entry.data.AB$unique.Line.ID = ifelse(BV.MC.Entry.data.AB$unique.Line.ID=="",
BV.MC.Entry.data.AB$`Variety`,
BV.MC.Entry.data.AB$unique.Line.ID)
BV.MC.Entry.data.AB$unique.Line.ID = ifelse(is.na(BV.MC.Entry.data.AB$unique.Line.ID),
BV.MC.Entry.data.AB$`Variety`,
BV.MC.Entry.data.AB$unique.Line.ID)
BV.MC.Entry.data.AB$unique.Line.ID = ifelse(is.na(BV.MC.Entry.data.AB$unique.Line.ID),
as.character(BV.MC.Entry.data.AB$Female.Pedigree),
BV.MC.Entry.data.AB$unique.Line.ID)
BV.MC.Entry.data.AB$unique.Line.ID = ifelse(BV.MC.Entry.data.AB$unique.Line.ID=="",
as.character(BV.MC.Entry.data.AB$Female.Pedigree),
BV.MC.Entry.data.AB$unique.Line.ID)
#remove spaces in all mathcing columns
BV.MC.Entry.data.AB$Pedigree = ifelse(BV.MC.Entry.data.AB$Pedigree=="",
as.character(BV.MC.Entry.data.AB$InbName),
BV.MC.Entry.data.AB$Pedigree)
BV.MC.Entry.data.AB$Pedigree = ifelse(is.na(BV.MC.Entry.data.AB$Pedigree),
as.character(BV.MC.Entry.data.AB$InbName),
BV.MC.Entry.data.AB$Pedigree)
BV.MC.Entry.data.AB$Pedigree = ifelse(is.na(BV.MC.Entry.data.AB$Pedigree),
as.character(BV.MC.Entry.data.AB$Variety),
BV.MC.Entry.data.AB$Pedigree)
BV.MC.Entry.data.AB$Pedigree = ifelse(BV.MC.Entry.data.AB$Pedigree=="",
as.character(BV.MC.Entry.data.AB$Variety),
BV.MC.Entry.data.AB$Pedigree)
BV.MC.Entry.data.AB$Pedigree = ifelse(BV.MC.Entry.data.AB$Pedigree=="",
as.character(BV.MC.Entry.data.AB$Female.Pedigree),
BV.MC.Entry.data.AB$Pedigree)
BV.MC.Entry.data.AB$Pedigree = ifelse(is.na(BV.MC.Entry.data.AB$Pedigree),
as.character(BV.MC.Entry.data.AB$Female.Pedigree),
BV.MC.Entry.data.AB$Pedigree)
BV.MC.Entry.data.AB$unique.Line.ID <- gsub("[[:space:]]", "", BV.MC.Entry.data.AB$unique.Line.ID)
BV.MC.Entry.data.AB$Pedigree <- gsub("[[:space:]]", "", BV.MC.Entry.data.AB$Pedigree)
######################################################
#import previous years peds and merge do this year
######################################################
# shdSlk1519<-read.xlsx(paste0(oldfd),1)
# shdSlk1519$InbName <- gsub("[[:space:]]", "", shdSlk1519$InbName)
# shdSlk1519$Variety <- gsub("[[:space:]]", "", shdSlk1519$Variety)
#
# shdSlk1519$pedigree <- gsub("[[:space:]]", "", shdSlk1519$pedigree)
#
# shdSlk1519$pedigree = ifelse(shdSlk1519$pedigree=="",
#                              as.character(shdSlk1519$InbName),
#                              shdSlk1519$pedigree)
#
# shdSlk1519$pedigree = ifelse(is.na(shdSlk1519$pedigree),
#                              as.character(shdSlk1519$InbName),
#                              shdSlk1519$pedigree)
# colnames(shdSlk1519)
# colnames(BV.MC.Entry.data.AB)
#
# df1=data.frame(BV.MC.Entry.data.AB[,c(5,40)]); colnames(df1)= c("Line.ID","unique.Line.ID")
# df2=data.frame(shdSlk1519[,c(9,7)]);colnames(df2)= c("Line.ID","unique.Line.ID")
#
#lines2020=rbind(df1, df2)
lines2020=BV.MC.Entry.data.AB[,c(6,56)]
colnames(lines2020)[1] = "Line.ID"
############################################################
#Coded line import
############################################################
to_search_in.female <- data.table(BV.MC.Entry.data.AB[!duplicated(BV.MC.Entry.data.AB$unique.Line.ID),c(56,6)])
colnames(to_search_in.female)=c("unique","pedigree")
to_search_with.female <- tibble(BV.MC.Entry.data.AB[!duplicated(BV.MC.Entry.data.AB$unique.Line.ID),c(56)])
colnames(to_search_with.female) = "unique_female_id"
to_search_in.female.order = order(to_search_in.female$pedigree)
to_search_in.female = to_search_in.female[to_search_in.female.order,]
to_search_with.female.order = order(to_search_with.female$unique_female_id)
to_search_with.female = to_search_with.female[to_search_with.female.order,]
linked.peds = to_search_in.female
linked.peds$pedigree = as.character(linked.peds$pedigree)
linked.peds$pedigree = ifelse(linked.peds$pedigree=="",
as.character(linked.peds$unique),
linked.peds$pedigree)
linked.peds$pedigree = ifelse(is.na(linked.peds$pedigree),
as.character(linked.peds$unique),
linked.peds$pedigree)
linked.peds = linked.peds[!duplicated(linked.peds$unique), ]
linked.peds$match = linked.peds$pedigree
BV.MC.Inbred <- openxlsx::read.xlsx(paste0("R:/Breeding/MT_TP/Models/Data/Department Data/NEW LINE CODES.xlsx"),1)
BV.MC.Inbred$Pedigre_Backup = BV.MC.Inbred$PEDIGREE
BV.MC.Inbred = BV.MC.Inbred[,c(1:3,21,4:20)]
to_search_in <- data.table(linked.peds[!duplicated(linked.peds$match),c(3)])
colnames(to_search_in)=c("unique")
to_search_with <- tibble(BV.MC.Inbred[!duplicated(BV.MC.Inbred$PEDIGREE),c(2,3)])
colnames(to_search_with) = c("Code","unique_ped_id")
#to_search_with.male <- tibble(BV.MC.Male[!duplicated(BV.MC.Male$match1),c(2)])
#colnames(to_search_with.male) = c("unique_male_id")
dim(to_search_with);dim(to_search_in)
# rm(BV.MC.Entry.data.AB)
# invisible(gc())
#
#n = nrow(to_search_with.male)
#for(batch in 1:nrow(to_search_with)){
#to_search_with.batch = to_search_with[batch,]
invisible(gc(reset=T)) #cleans memory "garbage collector"
memory.limit(size=15071)
digitDH = "((-)?B\\.DHB[0-9]*|(-)?B\\.DH[0-9]*|(-)?\\.DH-B[0-9]*|(-)?\\.DHB[0-9]*|(-)?\\.DH[0-9]*)"
linked.peds.beck = to_search_with %>%
dplyr::mutate(data = list(to_search_in) ) %>%
tidyr::unnest(data) %>%
dplyr::mutate(unique_ped_id_nchar = nchar(unique_ped_id) ) %>%
dplyr::mutate(unique_nchar = nchar(unique) ) %>%
dplyr::mutate(unique_ped_id_DH = (stringr::str_extract(digitDH, string = unique_ped_id) ) )%>%
#mutate(unique_ped_id_DH2 = gsub(".*?\\.(.*?)\\.*", x=unique_ped_id, value=T) ) %>%
dplyr::mutate(unique_DH = (stringr::str_extract(digitDH, string=unique) ) )%>%
dplyr::filter(unique_nchar <= (unique_ped_id_nchar+15)  )
linked.peds.beck2 = linked.peds.beck %>%
dplyr::mutate(unique_ped_id_DH_1 = ifelse((unique_ped_id_nchar < 10), as.matrix(grepl("\\/", x = unique )), F))
linked.peds.beck3 =  linked.peds.beck2 %>%
dplyr::filter((stringr::str_detect(unique, (stringr::coll(unique_ped_id)  )  )))  %>%
dplyr::filter(unique_ped_id_DH_1 != TRUE)
invisible(gc(reset=T)) #cleans memory "garbage collector"
linked.peds.beck4 =   linked.peds.beck3 %>%
dplyr::mutate(DH_Match = ifelse(unique_ped_id_DH == unique_DH , TRUE,FALSE) ) %>%
dplyr::mutate(DH_Match = ifelse(is.na(DH_Match), TRUE, DH_Match)) %>%
dplyr::filter(DH_Match != FALSE)
invisible(gc(reset=T)) #cleans memory "garbage collector"
linked.peds.beck4 = linked.peds.beck4 %>%
dplyr::select(Code,unique_ped_id,unique) %>%
dplyr::group_by(Code,unique) %>%
dplyr::summarise(strings = str_c(unique_ped_id, collapse = ", "))
rm(linked.peds.beck, linked.peds.beck2, linked.peds.beck3)
invisible(gc(reset=T)) #cleans memory "garbage collector"
linked.peds.beck = linked.peds.beck4 %>% tidyr::separate("strings", sep="[, ][ ]",
c("match1", "match2","match3", "match4","match5", "match6","match7", "match8","match9", "match10","match11", "match12","match13", "match14" ,"match15", "match16"),
extra="merge",
remove=F)
rm(linked.peds.beck4)
linked.peds.beck = dplyr::left_join(linked.peds.beck, BV.MC.Inbred[,c(2,3)], by=c("Code"="NEW.CODE"))
linked.peds.beck = linked.peds.beck[,c(20,1:19)]
linked.peds = dplyr::left_join(linked.peds[, c(1,2,3)], linked.peds.beck[, c(2,3)], by = c("match"="unique"))
#bind.linked.female.peds[[length(bind.linked.female.peds)+1]] = linked.female.peds
# rm(linked.female.peds, to_search_with.batch)
# }
# linked.female.peds = rbindlist(bind.linked.female.peds)
linked.peds$match = ifelse(!is.na(linked.peds$Code) , as.character(linked.peds$Code), linked.peds$match)
#############################################################
#############################################################
#############################################################
BV.MC.Inbred <- openxlsx::read.xlsx(paste0("R:/Breeding/MT_TP/Models/Data/Department Data/NEW LINE CODES.xlsx"),1)
BV.MC.Inbred$Pedigre_Backup = BV.MC.Inbred$PEDIGREE
BV.MC.Inbred = BV.MC.Inbred[,c(1:3,21,4:20)]
###run pedigree reduction function
#source("R:/Breeding/MT_TP/Models/R-Scripts/greplPeds.R")
newData=pedigreeReduce(data=BV.MC.Inbred, Codes=T)
BV.MC.Inbred = newData
# rm(data,newData)
#BV.MC.Inbred.slash = BV.MC.Inbred %>% dplyr::filter(grepl(, pattern="/") == TRUE)
to_search_in <- data.table(linked.peds[!duplicated(linked.peds$match),c(3)])
colnames(to_search_in)=c("unique")
to_search_with <- tibble(BV.MC.Inbred[!duplicated(BV.MC.Inbred$PEDIGREE),c(2,3)])
colnames(to_search_with) = c("Code","unique_ped_id")
#to_search_with.male <- tibble(BV.MC.Male[!duplicated(BV.MC.Male$match1),c(2)])
#colnames(to_search_with.male) = c("unique_male_id")
dim(to_search_with);dim(to_search_in)
rm(to_search_with.male, to_search_with.female, to_search_in.female, to_search_in.male, linked.peds.beck)
invisible(gc(reset=T)) #cleans memory "garbage collector"
#n = nrow(to_search_with.male)
#for(batch in 1:nrow(to_search_with)){
#to_search_with.batch = to_search_with[batch,]
linked.peds.save = linked.peds
linked.peds = linked.peds.save
linked.peds.beck = to_search_with %>%
dplyr::mutate(data = list(to_search_in) ) %>%
tidyr::unnest(data) %>%
dplyr::mutate(unique_ped_id_nchar = nchar(unique_ped_id) ) %>%
dplyr::mutate(unique_nchar = nchar(unique) ) %>%
dplyr::mutate(unique_ped_id_DH = (stringr::str_extract(digitDH, string = unique_ped_id) ) )%>%
#mutate(unique_ped_id_DH2 = gsub(".*?\\.(.*?)\\.*", x=unique_ped_id, value=T) ) %>%
dplyr::mutate(unique_DH = (stringr::str_extract(digitDH, string=unique) )) %>%
dplyr::filter(unique_nchar <= (unique_ped_id_nchar+15)  )
linked.peds.beck2 = linked.peds.beck %>%
mutate(unique_ped_id_DH_1 = ifelse((unique_ped_id_nchar < 10), as.matrix(grepl("\\/", x = unique )), F))
rm(linked.peds.beck); invisible(gc(reset=T))
linked.peds.beck3 =  linked.peds.beck2 %>%
dplyr::filter(  stringr(str_detect(unique, (stringr::coll(unique_ped_id)  )  ) ) )%>%
dplyr::filter(unique_ped_id_DH_1 != TRUE)
rm(linked.peds.beck2)
invisible(gc(reset=T)) #cleans memory "garbage collector"
linked.peds.beck4 =   linked.peds.beck3 %>%
dplyr::mutate(DH_Match = ifelse(unique_ped_id_DH == unique_DH , TRUE, FALSE) ) %>%
dplyr::mutate(DH_Match = ifelse(is.na(DH_Match), TRUE, DH_Match)) %>%
dplyr::filter(DH_Match != FALSE)
invisible(gc(reset=T)) #cleans memory "garbage collector"
linked.peds.beck4 = linked.peds.beck4 %>%
dplyr::select(Code,unique_ped_id,unique) %>%
dplyr::group_by(Code,unique) %>%
dplyr::summarise(strings = (stringr::str_c(unique_ped_id, collapse = ", ")))
rm(linked.peds.beck, linked.peds.beck2, linked.peds.beck3)
invisible(gc(reset=T)) #cleans memory "garbage collector"
linked.peds.beck = linked.peds.beck4 %>% tidyr::separate("strings", sep="[, ][ ]",
c("match1", "match2","match3", "match4","match5", "match6","match7", "match8","match9", "match10","match11", "match12","match13", "match14" ,"match15", "match16"),
extra="merge",
remove=F)
rm(linked.peds.beck4)
linked.peds.beck = dplyr::left_join(linked.peds.beck, BV.MC.Inbred[,c(2,3)], by=c("Code"="NEW.CODE"))
linked.peds.beck = linked.peds.beck[,c(20,1:19)]
colnames(linked.peds.beck)[2] = "CodeV2"
linked.peds = dplyr::left_join(linked.peds[, c(1,2,3,4)], linked.peds.beck[, c(2,3)], by = c("match"="unique"))
#bind.linked.female.peds[[length(bind.linked.female.peds)+1]] = linked.female.peds
# rm(linked.female.peds, to_search_with.batch)
# }
# linked.female.peds = rbindlist(bind.linked.female.peds)
linked.peds$match = ifelse(!is.na(linked.peds$CodeV2) , as.character(linked.peds$CodeV2), linked.peds$match)
linked.peds$match = ifelse(!is.na(linked.peds$Code) , as.character(linked.peds$Code), linked.peds$match)
linked.peds$Code = ifelse(is.na(linked.peds$Code) , as.character(linked.peds$CodeV2), linked.peds$Code)
# linked.peds = linked.peds[!duplicated(linked.peds$uniqued_id), ]
# write.xlsx(linked.peds,"C:/Users/jake.lamkey/Desktop/linked.male.female.nestedpeds.xlsx")
#
# #write.csv(x=BV.MC.Entry.data.AB, file="C:/Users/jake.lamkey/Desktop/BV.MC.Entry.data.AB.xlsx")
#
# #write.xlsx(x=BV.MC.Entry.data.AB, file="C:/Users/jake.lamkey/Desktop/BV.MC.Entry.data.AB.xlsx")
#
#
# linked.peds = read.xlsx("C:/Users/jake.lamkey/Desktop/linked.male.female.nestedpeds.xlsx")
#
linked.peds.save = linked.peds
linked.peds$match = as.character(linked.peds$match)
######################################################
#match and nest linked pedigress for export and review
######################################################
#if(doPedigreeChange){
# to_search_in.line <- data.table(linked.peds[!duplicated(linked.peds$match),c(1,3)])
# #colnames(to_search_in.female)=c("unique_female","female.pedigree")
#
# to_search_with.line <- tibble(linked.peds[!duplicated(linked.peds$match),c(3)])
# colnames(to_search_with.line) = "unique_line"
#
# #dim(to_search_in.female);dim(to_search_in.male);dim(to_search_with.male);dim(to_search_with.female)
#
# linked.line.peds = to_search_with.line %>%
#   mutate(data = list(to_search_in.line)) %>%
#   unnest(data) %>%
#   dplyr::filter(str_detect(unique_line, fixed(unique))) %>% #comparing with  to in
#   #select(unique_female,female.pedigree,unique_female_id) %>%
#   group_by(unique) %>% #should be the fixed effect
#   summarise(strings = str_c(unique_line, collapse = ", "))
#
# linked.line.peds = linked.line.peds %>% tidyr::separate("strings", sep="[, ][ ]",
#                                                         c("match1", "match2","match3", "match4","match5", "match6","match7", "match8","match9", "match10","match11", "match12","match13", "match14" ,"match15", "match16"),
#                                                         extra="merge",
#                                                         remove=F)
# #destfile7 = paste0(dp,year,"/linked.lines.nestedpeds.xlsx")
#
# linked.line.peds$match1 = ifelse(linked.line.peds$match1=="",
#                             as.character(linked.line.peds$uniqued.Line.ID),
#                             linked.line.peds$match1)
#
#linked.peds$match = linked.peds$match1
#linked.line.peds = linked.line.peds[,c(1,19,3,4:18)]
#linked.line.peds$match <- gsub("[[:space:]]", "", linked.line.peds$match)
linked.peds$match <- gsub("[[:space:]]", "", linked.peds$match)
#source("R:/Breeding/MT_TP/Models/R-Scripts/BreedStats/R/InbredNameLibrary.R")
patterns = InbredNameLibrary()
patterns = patterns[[1]]
#inbreds###################################################################
linked.peds$match = as.character(linked.peds$match)
match=stringr::str_detect(string = linked.peds$match, pattern = paste(patterns, collapse = "|"), negate=T)
match=data.frame(match)
for(i in 1:nrow(linked.peds)) {
if(match[i,1]==TRUE){
#print("yes")
linked.peds[i,3] = gsub(x=linked.peds[i,3], pattern=fixed("-.*"), replacement="") # add a period for using wildcards
linked.peds[i,3] = gsub(x=linked.peds[i,3], pattern=fixed("\\)"), replacement="") #escape parathesis with \\
}
}
#########################################################################################################
###################################Merge data with adjusted lines########################################
#########################################################################################################
BV.MC.Entry.data.AB$Level = ""
BV.MC.Entry.data.AB$Rep = ""
BV.MC.Entry.data.AB$`Book.Season` = gsub(x=BV.MC.Entry.data.AB$`Book.Season`,pattern="S: Corn",replacement="", fixed=T)
BV.MC.Entry.data.AB$`Book.Season` = as.numeric(BV.MC.Entry.data.AB$`Book.Season`) + 2000
#BV.MC.Entry$Yr = ""
#BV.MC.Entry$Loc = ""
BV.MC.Entry.data.AB = BV.MC.Entry.data.AB[ ,c(57,58,14,3,7,6,24,21,49,50,9,8,10,44,20,22,23,25,42,28,
27,41,33,45,46,48,37,47,1,21,24,36,38,40,39,43,31,32,34,
35,51,54,52,53,55,56)]
BV.MC.Entry.data.AB2020 = BV.MC.Entry.data.AB %>% dplyr::filter(Book.Season == 2020)
#BV.MC.Entry.data.AB = BV.MC.Entry.data.AB %>% dplyr::filter(Book.Season != 2020)
# qualdatbyYear = read.csv(paste0(fdp))
#
# qualdatbyYear2020 = qualdatbyYear %>% dplyr::filter(Yr == 2020)
# qualdatbyYear = qualdatbyYear %>% dplyr::filter(Yr != 2020)
#
# #qualday <- left_join(qualdatbyYear, BV.MC.Entry.data.AB[,c(11,12,4,10,41)],
# #                     by = c("Range"="Range", "Row"="Row", "Loc"="Field..", "EBN"="Entry.Book.Name"))
#
#
#
# ##############################################
# ##############################################
# #qualdatbyYear <- qualdatbyYear %>% dplyr::filter((Plot.Discarded) == "")
# qualdatbyYear <- qualdatbyYear %>% dplyr::filter(EBN != "TP20S_Filler",
#                                           EBN != "FILL",
#                                           EBN != "Filler")
#
# dim(qualdatbyYear)
#
# # qualday <- left_join(qualdatbyYear, BV.MC.Entry.data.AB[,c(3,2,8,9,44,1)], by = c("Range"="Range", "Row"="Row", "Loc"="Book.Name","EBN"="Entry.Book.Name"))
#
#
#
#
#
empty_as_na <- function(x){
if("factor" %in% class(x)) x <- as.character(x) ## since ifelse wont work with factors
ifelse(as.character(x)!="", x, NA)
}
#qualday$unique.Line.ID = ""
#qualday$InbName <- gsub("[[:space:]]", "", qualday$InbName)
#qualday$pedigree <- gsub("[[:space:]]", "", qualday$pedigree)
# qualdatbyYear$unique.Line.ID = ""
# qualdatbyYear = qualdatbyYear %>% mutate_each(funs(empty_as_na)) #make sure cells are na
#
# qualdatbyYear$unique.Line.ID = ifelse(is.na(qualdatbyYear$unique.Line.ID),
#                                       as.character(qualdatbyYear$InbName),
#                                       qualdatbyYear$unique.Line.ID)
colNameRe = c(   "Level"                ,
"Rep"                  ,
"Plot.Discarded"       ,
"EBN"                  ,
"InbName"              ,
"Pedigree"             ,
"Shd_50"               ,
"Slk_50"               ,
"Yr"                   ,
"Loc"                  ,
"Range"                ,
"Row"                  ,
"Entry"                ,
"Brace.Root"           ,
"SLK10"                ,
"SLK90"                ,
"SHD10"                ,
"SHD90"                ,
"Ear.Stalk"            ,
"Plt.Height"           ,
"EarHt"                ,
"Tillers"              ,
"Leaf.Angle"           ,
"SL.Rating"            ,
"RL.Rating"            ,
"Comments"             ,
"Shed.Rating"          ,
"Stand.Count"          ,
"RecId"                ,
"SLK50"                ,
"SHD50"                ,
"Pollen.Duration..GDUs.10..to.90..",
"Silk.Color"           ,
"Tassel.Extension"     ,
"Tassel.Branches"      ,
"Anther.Color"         ,
"Glume.Color"          ,
"Glume.Ring"           ,
"Leaf.Color"           ,
"Leaf.Texture"         ,
"NCLB"                 ,
"GLS"                  ,
"NCLB.2"               ,
"GOSS"                 ,
"Variety",
"unique.Line.ID")
colnames(BV.MC.Entry.data.AB) = colNameRe
#qualday = rbind(qualdatbyYear, BV.MC.Entry.data.AB)
qualday =  BV.MC.Entry.data.AB
#qualday = data.frame(qualday)
######################################################################################################
###################################REVIEW LINKED AND NESTED PEDIGREES BEFORE CONTINUING#########
#########################################################################################################
#IMPORT REVIEWED MALE AND FEMALE PEDIGREES
##########################################
#BV.MC.LINE<-read.xlsx2(paste0(dp, year, '/linked.lines.nestedpeds.update.xlsx'), 1, na="", header=TRUE)#all varieties to build the model
#BV.MC.Female$unique_female_id <- gsub("[[:space:]]", "", BV.MC.Female$unique_female_id)
#BV.MC.Male$unique_male_id <- gsub("[[:space:]]", "", BV.MC.Male$unique_male_id)
BV.MC.LINE = linked.peds[,c(1,3)]
#write.csv(BV.MC.Entry.data.AB,"")
######create male and female merge reduced and line_id list to us
rm(InbName.checknames,BV.MC.Entry.data.AB.checkfilter.InbName.duplciate,BV.MC.Entry.data.AB.checkfilter.InbName,
BV.MC.Entry.data.AB.checkfilter,BV.MC.Female.Line_ID,BV.MC.Female.Line_ID.entry,BV.MC.Female.reduced,BV.MC.Female.reduced.entry,
BV.MC.Male.Line_ID,BV.MC.Male.Line_ID.entry,BV.MC.Male.reduced,BV.MC.Male.reduced.entry,
to_search_in.female,to_search_in.male,to_search_with.female,to_search_with.male,linked.female.peds,linked.male.peds)
rm(BV.MC.Entry.filterA, BV.MC.Entry.filterB)
invisible(gc(reset=T)) #cleans memory "garbage collector"
qualday$unique.Line.ID <- suppressWarnings(suppressMessages(plyr::revalue(as.character(qualday$unique.Line.ID), c('65125'=	'065125',' 65125'=	'065125', '56460'=	'056460', '54530'=	'054530', '56460' = '056460',
'54530'=	'054530', '54245'=	'054245', '54233'=	'054233','46358'=	'046358',
'46358'=	'046358', '37186'=	'037186', '26507'=	'026507','26076'=	'026076',
'16360'=	'016360', '16360'=	'016360', '16088'=	'016088','16088'=	'016088', '50'='050' ))))
lines2020 <- dplyr::left_join(qualday, BV.MC.LINE, by=c("unique.Line.ID"="unique"),keep=F);dim(lines2020)
#write.csv(lines2020,"P:/Temp/lines2020.csv" ,row.names=F)
#check for missing male or female pedigree the can
#BV.MC.Entry.data.AB.forReview = BV.MC.Entry.data.AB[,-c(3,5,6,32,33,14,15,8,9)]
#lines2020.forReview =lines2020[is.na(lines2020$match1.1),]
#BV.MC.Entry.data.AB.forReview.female=BV.MC.Entry.data.AB.forReview.female[!duplicated(BV.MC.Entry.data.AB.forReview.female$Pedigree),]
#write.csv(BV.MC.Entry.data.AB.forReview,"R:/Breeding/MT_TP/Models/Data/Department Data/2020/BV.MC.Entry.data.AB.forReview.csv")
#wb<-createWorkbook(type="xlsx")
#CellStyle(wb, dataFormat=NULL, alignment=NULL,
#          border=NULL, fill=NULL, font=NULL)
#Male <- createSheet(wb, sheetName = "Male")
#Female <- createSheet(wb, sheetName = "Female")
#addDataFrame(data.frame(BV.MC.Entry.data.AB.forReview.female),Female, startRow=1, startColumn=1,row.names=F)
#addDataFrame(data.frame(BV.MC.Entry.data.AB.forReview.male),Male, startRow=1, startColumn=1,row.names=F)
#saveWorkbook(wb, "R:/Breeding/MT_TP/Models/Data/Department Data/2020/BV.MC.Entry.data.AB.forReview.xlsx")
rm(BV.MC.Entry, BV.MC.Entry.data, BV.MC.Entry.data.AB, BV.MC.LINE, df1, df2, linked.line.peds, qualdatbyYear,
to_search_in.line, to_search_with.line, shdSlk1519, qualday)
invisible(gc(reset=T)) #cleans memory "garbage collector"
#colnames(lines2020)[16] = "LINE"
colnames(lines2020)[47] = "LINE"
#qualdat<-read.xlsx('R:/Breeding/MT_TP/Models/Data/Shd_slk/tblSlkShdGDUs.xlsx',1, header=T)#all varieties to build the model
#tblFlowerData_JL.xlsx
#levels(qualdat$InbName)#LEvels before
######convert Industry names to Becks names
industryNames = InbredNameLibrary()
industryNames = industryNames[[2]]
lines2020$LINE <- suppressWarnings(suppressMessages(plyr::revalue(as.character(lines2020$LINE), industryNames)))
#industry name to inbred name conversion
#levels(as.factor(qualdat$InbName)) #Levels After
#levels(as.factor(qualdat$loc))
#write.csv(qualdat,"qualdat.csv")
#qualdat <- qualdat[-c(3430,3428,3429,3427),] #may need to change these rows if qualdat was sorted prior; removed 2116 datapoints (not true data?)
qual.count<-data.table(lines2020)#convert to a data.table for easier processing
#z<-stat.desc(lines2020) # get some stats on dataset
counts <- qual.count[, .(rowCount = .N), by = LINE]; colnames(counts)=c("LINE","Observations")  #counts observations per InbName
#counts.loc<-qual.count[, .(rowCount = .N), by = c("InbName","loc","yr")] #counts observations per InbName
#qualdat.singles <- counts %>% dplyr::filter(Observations!=1);colnames(qualdat.singles) = c("LINE", "Observations") #filter only single values for model buliding
#head(counts);tail(counts) #count the number of observations per InbName
######Check to ensure data imported correctly
#str(lines2020)
#head(lines2020)
#tail(lines2020)
######Examine distribution of of all the data first, will do more in depth distributions later
######Remove observations that are not true data...
attach(lines2020) # attached dataset so I dont need to address the dataset in the functions
hist(Shd_50 , col="gold") #distrubiton on all values
hist(Slk_50, col="green") #distrubtion on all values
boxplot(Shd_50~Level, xlab="Trial", ylab="Degrees obs_shd", main="Degrees obs_shd by Trial", col="pink")
boxplot(Slk_50~Level, xlab="Trial", ylab="Degrees obsSLK", main="Degrees obsSLK by Trial", col="pink")
boxplot(Shd_50~Yr, xlab="yr", ylab="Degrees obs_shd", main="Degrees obs_shd by yr", col="pink")
boxplot(Slk_50~Yr, xlab="yr", ylab="Degrees obsSLK", main="Degrees obsSLK by yr", col="pink")
boxplot(Shd_50~Loc, xlab="Location", ylab="Degrees obs_shd", main="Degrees obs_shd by Location", col="pink")
boxplot(Slk_50~Loc, xlab="Location", ylab="Degrees obsSLK", main="Degrees obsSLK by Location", col="pink")
######Rename variables for ease of use
#lines2020$GDU_slk50 = as.numeric(Slk_50)
#lines2020$GDU_shd50 = as.numeric(Shd_50)
lines2020$FIELD = as.factor(Loc)
lines2020$YEAR = as.factor(Yr)
lines2020$REP = as.factor(Rep)
lines2020$EXP = as.factor(EBN)
lines2020$LINE = as.factor(LINE)
qualdat.mt <- lines2020 %>% ddplyr::filter(Loc == "Marshalltown") #filter only marshalltown lines
qualdat.olivia <- lines2020 %>% dplyr::filter(Loc == "Olivia") #filter only olivia lines
qualdat.atlanta <- lines2020 %>% dplyr::filter(Loc == "Atlanta") #filter only olivia lines
# require(agricolae)
# aggregate(lines2020[,c("Slk_50","Shd_50")], by=list(FIELD=lines2020$FIELD),skewness)#calculate skewness for each effect
#levelstodrop<-c("Alanta")#drop any location variables,
#for(i in levelstodrop){qualdat <- droplevels(qualdat[grep( i,qualdat[ ,"loc"], invert=TRUE), ] )}
detach(lines2020)
##############################
linesYear = lines2020 %>% dplyr::filter( (dplyr::between(as.numeric(as.character(YEAR)), l_year, h_year)))
#linesreploc = lines2020 %>% dplyr::filter(YEAR == Current)
qualdat.df = linesYear #choose your dataset for the model
#write.csv(qualdat.df,"PropandChoice.csv",na="")
library(BreedStats)
x = "9_2_2021"
hdp = paste0('R:/Breeding/MT_TP/Models/Data/Shd_slk/Becks_OBS ',x, ".csv")
gdp = paste0('R:/Breeding/MT_TP/Models/Data/Shd_slk/Becks_OBS GOSS ',x, ".csv")
var4=2021
var2 = 2017
var3=2021
dpf = "C:/Users/jake.lamkey/Documents/Inbred Data_" #"R:/Breeding/MT_TP/Models/shed_silk/Inbred Data_",
#dpf = "R:/Breeding/MT_TP/Models/shed_silk/Inbred Data_"
year= var4
l_year = var2
h_year = var3
suppressWarnings(suppressMessages(
inbredChar(
dpf = dpf, #"C:/Users/jake.lamkey/Documents/Inbred Data_", #"R:/Breeding/MT_TP/Models/shed_silk/Inbred Data_",
gdp = gdp,
hdp = hdp,
year= var4,
l_year = var2,
h_year = var3,
doAdjInbredData = T,
simulate=F
)))
?ranef
?coef
?fitted
?vc
??vc
?tstrsplit
?:=
?setDT
?map
?image_join
library(magick)
?image_join
?dir.create
?image_read
?image_write
